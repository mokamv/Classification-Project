{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat(\"MNist_ttt4275/data_all.mat\", spmatrix=False)\n",
    "\n",
    "# Extract the data\n",
    "testv = data[\"testv\"]\n",
    "testlab = data[\"testlab\"].flatten()\n",
    "num_test = data[\"num_test\"][0][0]\n",
    "\n",
    "trainv = data[\"trainv\"]\n",
    "trainlab = data[\"trainlab\"].flatten()\n",
    "num_train = data[\"num_train\"][0][0]\n",
    "\n",
    "vec_size = data[\"vec_size\"][0][0]\n",
    "\n",
    "# Create vector consisting of test and train images\n",
    "test_images = []\n",
    "train_images = []\n",
    "\n",
    "for i in range(num_test):\n",
    "   test_images.append(testv[i, :].reshape((28,28)))\n",
    "   \n",
    "for i in range(num_train):\n",
    "   train_images.append(trainv[i, :].reshape((28,28)))\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "train_images = np.array(train_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessarry functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates error rate\n",
    "\n",
    "def error_rate(predicted_labels, true_labels):\n",
    "    n = len(predicted_labels)\n",
    "    error = 0\n",
    "    for i in range (n):\n",
    "        if predicted_labels[i] != true_labels[i]: error += 1\n",
    "    return error/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "def confusion_matrix(predicted_labels):\n",
    "    predicted_labels = np.array(predicted_labels).flatten()\n",
    "\n",
    "    confusion_matrix = np.zeros((10, 10)) #TP, FP, FN, TN\n",
    "    missclassified_idx = []\n",
    "\n",
    "    for i in range(num_test):\n",
    "        confusion_matrix[testlab[i]][[predicted_labels[i]]] += 1\n",
    "        if testlab[i] != predicted_labels[i]:\n",
    "            missclassified_idx.append(i)\n",
    "\n",
    "    print(np.array_str(confusion_matrix, precision=2, suppress_small=True))\n",
    "\n",
    "    return missclassified_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1 a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual nearest Neighborhood classifier\n",
    "\n",
    "def nnclassifier(new_image):\n",
    "    nearest_class = trainlab[0]\n",
    "    current_distance = np.linalg.norm(train_images[0] - new_image)\n",
    "    for i in range(1, num_train):\n",
    "        new_distance = np.linalg.norm(train_images[i] - new_image)\n",
    "        if current_distance > new_distance:\n",
    "            current_distance = new_distance\n",
    "            nearest_class = trainlab[i]\n",
    "    return nearest_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nearest Neighborhood Classifier using cdist\n",
    "def nnclassifier():\n",
    "    n_chunks = num_test//1000 # number of chunks\n",
    "    predicted_labels = []\n",
    "    for i in range(n_chunks):\n",
    "        test_chunk = testv[1000*i: 1000*(i+1)] # extract chunks\n",
    "        distance_matrix = cdist(test_chunk, trainv, metric='euclidean') # Calculates the euclidean distance between each image in the test chunk and all the training images\n",
    "        nearest_indices = np.argmin(distance_matrix, axis=1) # finds the indices of the images that where closest\n",
    "        predicted_labels.extend(trainlab[nearest_indices]) # finds the label of the image that was closest\n",
    "    return predicted_labels\n",
    "\n",
    "predicted_labels = nnclassifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 973.    1.    1.    0.    0.    1.    3.    1.    0.    0.]\n",
      " [   0. 1129.    3.    0.    1.    1.    1.    0.    0.    0.]\n",
      " [   7.    6.  992.    5.    1.    0.    2.   16.    3.    0.]\n",
      " [   0.    1.    2.  970.    1.   19.    0.    7.    7.    3.]\n",
      " [   0.    7.    0.    0.  944.    0.    3.    5.    1.   22.]\n",
      " [   1.    1.    0.   12.    2.  860.    5.    1.    6.    4.]\n",
      " [   4.    2.    0.    0.    3.    5.  944.    0.    0.    0.]\n",
      " [   0.   14.    6.    2.    4.    0.    0.  992.    0.   10.]\n",
      " [   6.    1.    3.   14.    5.   13.    3.    4.  920.    5.]\n",
      " [   2.    5.    1.    6.   10.    5.    1.   11.    1.  967.]]\n"
     ]
    }
   ],
   "source": [
    "missclassified_idx = confusion_matrix(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0309"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rate(predicted_labels, testlab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1 b)\n",
    "Plotting some misclassified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual label is:  8\n",
      "Predicted label is:  5\n",
      "Actual label is:  4\n",
      "Predicted label is:  1\n",
      "Actual label is:  9\n",
      "Predicted label is:  7\n",
      "Actual label is:  2\n",
      "Predicted label is:  7\n",
      "Actual label is:  6\n",
      "Predicted label is:  4\n"
     ]
    }
   ],
   "source": [
    "def image_info(idx):\n",
    "    print(\"Actual label is: \", testlab[idx])\n",
    "    print(\"Predicted label is: \", predicted_labels[idx])\n",
    "    # plt.imshow(test_images[idx], cmap=\"gray\")\n",
    "    # plt.show()\n",
    "    \n",
    "image_info(missclassified_idx[3])\n",
    "image_info(missclassified_idx[4])\n",
    "image_info(missclassified_idx[5])\n",
    "image_info(missclassified_idx[6])\n",
    "image_info(missclassified_idx[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2 a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "M = 64\n",
    "train_v = {}\n",
    "C = []\n",
    "\n",
    "for i in np.unique(trainlab):\n",
    "    train_v[i] = trainv[trainlab == i]\n",
    "\n",
    "for i in train_v.keys():\n",
    "    kmeans = KMeans(n_clusters=M, random_state=42)\n",
    "    _ = kmeans.fit_predict(train_v[i]) # \n",
    "    C.extend(kmeans.cluster_centers_) #Extrancts cluster centers and ads them to C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifying the elements using clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nearest Neighborhood Classifier using cdist\n",
    "def nnclassifier_clustering():\n",
    "    all_labels = np.concatenate([[i]*64 for i in range(10)])  # 64 labels per digit\n",
    "    predicted_labels = []\n",
    "\n",
    "    n_chunks = num_test//1000\n",
    "    for i in range(n_chunks):\n",
    "        test_chunk = testv[1000*i: 1000*(i+1)]\n",
    "        distance_matrix = cdist(test_chunk, C, metric='euclidean')\n",
    "        nearest_indices = np.argmin(distance_matrix, axis=1)\n",
    "        predicted_labels.extend(all_labels[nearest_indices])\n",
    "        \n",
    "    return predicted_labels\n",
    "\n",
    "predicted_labels_clustering = nnclassifier_clustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 966.    1.    3.    1.    0.    4.    3.    1.    0.    1.]\n",
      " [   0. 1126.    3.    1.    0.    0.    3.    0.    1.    1.]\n",
      " [   9.    8.  979.    8.    1.    0.    3.   11.   12.    1.]\n",
      " [   0.    0.    7.  940.    1.   32.    0.    6.   17.    7.]\n",
      " [   1.    6.    2.    0.  922.    0.   10.    4.    3.   34.]\n",
      " [   3.    1.    0.   20.    2.  845.    9.    1.    7.    4.]\n",
      " [   8.    3.    2.    0.    3.    3.  935.    0.    3.    1.]\n",
      " [   0.   20.    8.    0.    4.    1.    0.  961.    2.   32.]\n",
      " [   5.    1.    3.   11.    3.   20.    2.    6.  917.    6.]\n",
      " [   5.    6.    4.    5.   30.    1.    1.   19.    6.  932.]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "confusion_matrix(predicted_labels_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0477"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rate(predicted_labels_clustering, testlab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN with K = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K - Nearest Neighborhood Classifier using cdist and K = 7\n",
    "def KNN_classifier(k = 7):\n",
    "    n_chunks = num_test//1000\n",
    "    predicted_labels = []\n",
    "    for i in range(n_chunks):\n",
    "        test_chunk = testv[1000*i: 1000*(i+1)]\n",
    "        distance_matrix = cdist(test_chunk, trainv, metric='euclidean')\n",
    "        k_nearest_indices = np.argpartition(distance_matrix, k)[:, :k] # returns the indices of the k closest images\n",
    "\n",
    "        for test_idx in range(len(test_chunk)):\n",
    "            nearest_labels = trainlab[k_nearest_indices[test_idx]]\n",
    "            counts = np.bincount(nearest_labels)\n",
    "            most_frequent_label = np.argmax(counts)\n",
    "            predicted_labels.append(most_frequent_label)\n",
    "\n",
    "    return predicted_labels\n",
    "\n",
    "predicted_labels_KNN = KNN_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 974.    1.    1.    0.    0.    1.    2.    1.    0.    0.]\n",
      " [   0. 1133.    2.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [  11.    8.  988.    2.    1.    0.    2.   16.    4.    0.]\n",
      " [   0.    3.    2.  976.    1.   12.    1.    7.    4.    4.]\n",
      " [   1.    8.    0.    0.  945.    0.    5.    1.    1.   21.]\n",
      " [   5.    0.    0.    8.    2.  866.    4.    1.    2.    4.]\n",
      " [   6.    3.    0.    0.    3.    2.  944.    0.    0.    0.]\n",
      " [   0.   25.    3.    0.    1.    0.    0.  989.    0.   10.]\n",
      " [   6.    4.    6.   11.    7.   12.    1.    6.  916.    5.]\n",
      " [   5.    6.    3.    6.    8.    4.    1.   11.    2.  963.]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "confusion_matrix(predicted_labels_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0306"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rate(predicted_labels_KNN, testlab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
